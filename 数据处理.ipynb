{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"data\\main\\df_train_b1.csv\", index_col=0)\n",
    "test_data = pd.read_csv('data\\main\\df_test_b1.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 要读入除了main之外的数在此处添加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = [\"data\\detail\\df_basic_b1.csv\",\n",
    "             \"data\\detail\\df_corp_b1.csv\",\n",
    "             \"data\\detail\\df_judicial_b1.csv\",\n",
    "             \"data\\detail\\df_loan2_b1.csv\",\n",
    "             \"data\\detail\\df_query_b1.csv\"\n",
    "             ]\n",
    "for filename in filenames:\n",
    "    temp = pd.read_csv(filename)\n",
    "    train_data = pd.merge(train_data, temp, on=\"cust_id\",\n",
    "                          how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "    test_data = pd.merge(test_data, temp, on=\"cust_id\",\n",
    "                         how=\"left\", suffixes=(\"\", \"_y\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['nan_num'] = (train_data == 0).astype(int).sum(axis=1)\n",
    "# test_data['nan_num'] = (test_data == 0).astype(int).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['basic_2',\n",
    "    'basic_3',\n",
    "    'basic_4',\n",
    "    'loan1_1',\n",
    "    'overdue_19',\n",
    "    'basic_8',\n",
    "    'basic_9',\n",
    "    'basic_11',\n",
    "    'basic_15',]\n",
    "\n",
    "train_data.drop(drop_col, inplace=True,axis=1)\n",
    "test_data.drop(drop_col, inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loan1表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "\n",
    "    import pandas as pd\n",
    "    temp_df = pd.read_csv(\"./data/detail/df_loan1_b1.csv\")\n",
    "\n",
    "    def chuli_loan(df, colname, ways):\n",
    "        cust_id = list(range(len(set(df['cust_id']))))\n",
    "        res_df = pd.DataFrame({'cust_id': cust_id})\n",
    "        \n",
    "        if 'mean' in ways:\n",
    "            res_df[colname+'_mean'] = df.groupby('cust_id')[colname].mean()\n",
    "        if 'sum' in ways:\n",
    "            res_df[colname+'_sum'] = df.groupby('cust_id')[colname].sum()\n",
    "        if 'count' in ways:\n",
    "            res_df[colname+'_count'] = df.groupby('cust_id')[colname].count()\n",
    "        if 'std' in ways:\n",
    "            res_df[colname+'_std'] = df.groupby('cust_id')[colname].std()\n",
    "        if 'min' in ways:\n",
    "            res_df[colname+'_min'] = df.groupby('cust_id')[colname].min()\n",
    "        if 'diff_std' in ways:\n",
    "            res_df[colname+'_diff_std'] = df.groupby('cust_id')[colname].apply(\n",
    "                lambda x: x.sort_values(ascending=True).diff()[2:].std())\n",
    "        return res_df\n",
    "\n",
    "    for colname in ['loan1_2', 'loan1_3', 'loan1_7', 'loan1_9']:\n",
    "        df = chuli_loan(temp_df, colname, ('sum',))\n",
    "        train_data = pd.merge(train_data, df, on=\"cust_id\",\n",
    "                              how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "        test_data = pd.merge(test_data, df, on=\"cust_id\",\n",
    "                             how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "    # df = chuli_loan(temp_df, 'date_3', ('count',))\n",
    "    # train_data = pd.merge(train_data, df, on=\"cust_id\",\n",
    "    #                       how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "    # test_data = pd.merge(test_data, df, on=\"cust_id\",\n",
    "    #                      how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "    # df = chuli_loan(temp_df, 'date_1', ('min',))\n",
    "    # train_data = pd.merge(train_data, df, on=\"cust_id\",\n",
    "    #                       how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "    # test_data = pd.merge(test_data, df, on=\"cust_id\",\n",
    "    #                      how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "    # df = chuli_loan(temp_df, 'loan1_10', ('mean',))\n",
    "    # train_data = pd.merge(train_data, df, on=\"cust_id\",\n",
    "    #                       how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "    # test_data = pd.merge(test_data, df, on=\"cust_id\",\n",
    "    #                      how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "    # df = chuli_loan(temp_df, 'loan1_11', ('sum',))\n",
    "    # train_data = pd.merge(train_data, df, on=\"cust_id\",\n",
    "    #                       how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "    # test_data = pd.merge(test_data, df, on=\"cust_id\",\n",
    "    #                      how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "    # df = chuli_loan(temp_df, 'loan1_12', ('sum',))\n",
    "    # train_data = pd.merge(train_data, df, on=\"cust_id\",\n",
    "    #                       how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "    # test_data = pd.merge(test_data, df, on=\"cust_id\",\n",
    "    #                      how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "    train_data.to_csv('./data/df_train.csv')\n",
    "    test_data.to_csv('./data/df_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = temp_df.dropna(axis=0,subset = [\"date_1\"])\n",
    "# data['date2-date1'] = data['date_2'] - data['date_1']\n",
    "# data['date3-date2'] = data['date_3'] - data['date_2']\n",
    "# data['dateinterval_max'] = data[['date2-date1','date3-date2']].max(axis=1)\n",
    "# data = data.groupby('cust_id').agg({'date_2':['count'],'date_3':['count'],'dateinterval_max':['mean']})\n",
    "# train_data = pd.merge(train_data, data, on=\"cust_id\",\n",
    "#                           how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "# test_data = pd.merge(test_data, data, on=\"cust_id\",\n",
    "#                          how=\"left\", suffixes=(\"\", \"_y\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delnan(df):\n",
    "    df = df.dropna(how=\"all\", axis=1)  # 删除全是空值的列\n",
    "    df = df.fillna(-99)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = delnan(train_data)\n",
    "df_test = delnan(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理-99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.replace(-99, -1, inplace=True)\n",
    "# df_test.replace(-99, -1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析（效果不好）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# full_col_name = list(df_train.columns)\n",
    "# pca_col=[i for i in full_col_name if \"loan\" in i]\n",
    "\n",
    "# modelPCA=PCA(n_components=0.9)\n",
    "# temp=modelPCA.fit_transform(df_train[pca_col])\n",
    "# temp1=modelPCA.transform(df_test[pca_col])\n",
    "# for i in range(temp.shape[1]):\n",
    "#     df_train['loan_pca'+str(i)]=temp[:,i]\n",
    "#     df_test['loan_pca'+str(i)]=temp1[:,i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理分类变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_way = \"no\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转化为one-hot编码（不宜采用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_one_hot(df, colnames):\n",
    "    df = pd.get_dummies(df, columns=colnames)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类型计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_count_cols = ['industry', 'scope', 'basic_13']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def type_count(cols):\n",
    "#     global df_train, df_test\n",
    "#     df1 = df_train[['cust_id']+cols]\n",
    "#     df2 = df_test[['cust_id']+cols]\n",
    "#     df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "#     for i in cols:\n",
    "#         temp_df = df.groupby(i)['cust_id'].count()\n",
    "#         temp_df = pd.DataFrame({(i+\"_num\"): temp_df})\n",
    "#         df = pd.merge(df, temp_df, on=i, how=\"left\")\n",
    "#         del df[i], df1[i], df2[i]\n",
    "#     df_train = pd.merge(df_train, df, on=\"cust_id\",\n",
    "#                         how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "#     df_test = pd.merge(df_test, df, on=\"cust_id\",\n",
    "#                        how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "\n",
    "# type_count(type_count_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 证据权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cal_woe(df, df_no_label, x_cols, y_col):\n",
    "    for i in x_cols:\n",
    "        x_set = pd.unique(df[i])\n",
    "        x1_set = pd.unique(df_no_label[i])\n",
    "        for j in x1_set:\n",
    "            if j not in x_set:\n",
    "                df_no_label[i].replace(j, 0.03, inplace=True)\n",
    "                print(i, j, '不存在')\n",
    "        for j in x_set:\n",
    "            woe = np.mean(df[df[i] == j][y_col])\n",
    "            if woe >= 0.1:\n",
    "                n = np.sum(df[df[i] == j][y_col])\n",
    "                print(i, '列：', j, ' 共有', int(n/woe), '个,其中',\n",
    "                      int(n), '个label为1,woe为', woe, sep=\"\")\n",
    "            df[i].replace(j, woe, inplace=True)\n",
    "            df_no_label[i].replace(j, woe, inplace=True)\n",
    "    return df, df_no_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_col = [\"basic_1\",\n",
    "            \"basic_10\",\n",
    "            \"basic_12\",\n",
    "            \"basic_14\",\n",
    "            \"loan1_16\",\n",
    "            \"loan1_20\",\n",
    "            \"loan1_23\",\n",
    "            \"loan1_25\", ]\n",
    "\n",
    "# df_train,df_test=cal_woe(df_train,df_test,type_col,\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cat_way == \"auto\" or cat_way == \"no\":\n",
    "    type_col = [\"basic_1\",\n",
    "                \"basic_10\",\n",
    "                \"basic_12\",\n",
    "                \"basic_14\",\n",
    "                \"loan1_16\",\n",
    "                \"loan1_20\",\n",
    "                \"loan1_23\",\n",
    "                \"loan1_25\",\n",
    "                \"loan2_1_y\",\n",
    "                \"query_2_y\",\n",
    "                \"query_3_y\",\n",
    "                \"query_4_y\",\n",
    "                \"query_5_y\",\n",
    "                \"query_6_y\", ]\n",
    "if cat_way == \"manual\":\n",
    "    woe_col = ['basic_1',\n",
    "               'basic_5',\n",
    "               'basic_6',\n",
    "               'basic_10',\n",
    "               'loan1_16',\n",
    "               'loan1_20',\n",
    "               'loan1_25',\n",
    "               'loan1_23',\n",
    "               'loan1_32',\n",
    "               'loan2_4',\n",
    "               'loan2_6',\n",
    "               'overdue_2',\n",
    "               'overdue_20',\n",
    "               'overdue_21',\n",
    "               'overdue_26',\n",
    "               'overdue_27',\n",
    "               'query_1',\n",
    "               'query_2',\n",
    "               'query_3',\n",
    "               'query_4',\n",
    "               'query_6',\n",
    "               'query_7',\n",
    "               'query_8',\n",
    "               'query_10',\n",
    "               'query_11', ]\n",
    "\n",
    "    onehot_col = ['basic_12',\n",
    "                  'basic_14',\n",
    "                  'loan1_8',\n",
    "                  'loan1_9',\n",
    "                  'overdue_1',\n",
    "                  'overdue_3',\n",
    "                  'overdue_4',\n",
    "                  'overdue_5',\n",
    "                  'overdue_6',\n",
    "                  'overdue_7',\n",
    "                  'overdue_8',\n",
    "                  'overdue_9',\n",
    "                  'overdue_10',\n",
    "                  'overdue_11',\n",
    "                  'overdue_12',\n",
    "                  'overdue_14',\n",
    "                  'overdue_15',\n",
    "                  'overdue_16',\n",
    "                  'overdue_17',\n",
    "                  'overdue_18',\n",
    "                  'overdue_22',\n",
    "                  'overdue_23',\n",
    "                  'overdue_24',\n",
    "                  'overdue_25',\n",
    "                  'overdue_28',\n",
    "                  'overdue_29',\n",
    "                  'query_5',\n",
    "                  'query_9', ]\n",
    "\n",
    "    df_train, df_test = cal_woe(df_train, df_test, woe_col, \"label\")\n",
    "    df_train = to_one_hot(df_train, onehot_col)\n",
    "    df_test = to_one_hot(df_test, onehot_col)\n",
    "    for i in df_train.columns:\n",
    "        if i not in df_test.columns:\n",
    "            df_test[i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_col_name = list(df_train.columns)\n",
    "basic_col = [i for i in full_col_name if \"basic\" in i]\n",
    "loan_col = [i for i in full_col_name if \"loan\" in i]\n",
    "overdue_col = [i for i in full_col_name if \"overdue\" in i]\n",
    "query_col = [i for i in full_col_name if \"query\" in i]\n",
    "judicial_col = [i for i in full_col_name if \"judicial\" in i]\n",
    "date_col = [i for i in full_col_name if \"date\" in i]\n",
    "# loan_pca_col = [i for i in full_col_name if \"loan_pca\" in i]\n",
    "\n",
    "# for i in judicial_col:\n",
    "#     df_train[i].astype(\"float\")\n",
    "#     df_test[i].astype(\"float\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rank化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(rank_col):\n",
    "    global df_train, df_test\n",
    "    df1 = df_train[['cust_id']+rank_col]\n",
    "    df2 = df_test[['cust_id']+rank_col]\n",
    "    df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "    for i in rank_col:\n",
    "        df[i] = np.argsort(df[i])\n",
    "        del df_test[i]\n",
    "        del df_train[i]\n",
    "    df_train = pd.merge(df_train, df, on=\"cust_id\",\n",
    "                        how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "    df_test = pd.merge(df_test, df, on=\"cust_id\",\n",
    "                       how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "\n",
    "a = ['loan1_1', 'loan1_3', 'loan1_7', 'loan1_9']\n",
    "b = ['_sum', '_mean']\n",
    "c = []\n",
    "for i in a:\n",
    "    for j in b:\n",
    "        c.append(i+j)\n",
    "# rank(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(rank_col):\n",
    "    global df_train, df_test\n",
    "    df1 = df_train[['cust_id']+rank_col]\n",
    "    df2 = df_test[['cust_id']+rank_col]\n",
    "    df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "    for i in rank_col:\n",
    "        df[i] = (df[i]-np.min(df[i]))/(np.max(df[i])-np.min(df[i]))\n",
    "        del df_test[i]\n",
    "        del df_train[i]\n",
    "    df_train = pd.merge(df_train, df, on=\"cust_id\",\n",
    "                        how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "    df_test = pd.merge(df_test, df, on=\"cust_id\",\n",
    "                       how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "\n",
    "# norm([i for i in loan_col if i not in type_col and 'count' not in i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stand(rank_col):\n",
    "    global df_train, df_test\n",
    "    df1 = df_train[['cust_id']+rank_col]\n",
    "    df2 = df_test[['cust_id']+rank_col]\n",
    "    df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "    for i in rank_col:\n",
    "        df[i] = (df[i]-np.mean(df[i], axis=0))/np.std(df[i], axis=0)\n",
    "        del df_test[i]\n",
    "        del df_train[i]\n",
    "    df_train = pd.merge(df_train, df, on=\"cust_id\",\n",
    "                        how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "    df_test = pd.merge(df_test, df, on=\"cust_id\",\n",
    "                       how=\"left\", suffixes=(\"\", \"_y\"))\n",
    "\n",
    "\n",
    "# stand([i for i in loan_col if i not in type_col and 'count' not in i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置哪些x作为模型自变量输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自变量个数为 81\n",
      "['basic_1', 'basic_5', 'basic_6', 'basic_7', 'basic_10', 'basic_12', 'basic_13', 'basic_14', 'basic_1_y', 'basic_2_y', 'basic_3_y', 'loan1_2', 'loan1_3', 'loan1_4', 'loan1_5', 'loan1_6', 'loan1_7', 'loan1_8', 'loan1_9', 'loan1_10', 'loan1_11', 'loan1_12', 'loan1_13', 'loan1_14', 'loan1_15', 'loan1_16', 'loan1_17', 'loan1_18', 'loan1_19', 'loan1_20', 'loan1_21', 'loan1_22', 'loan1_23', 'loan1_24', 'loan1_25', 'loan1_26', 'loan1_27', 'loan1_28', 'loan1_29', 'loan1_30', 'loan1_31', 'loan1_32', 'loan1_33', 'loan2_1', 'loan2_2', 'loan2_3', 'loan2_4', 'loan2_5', 'loan2_6', 'loan2_7', 'loan2_8', 'loan2_9', 'loan2_10', 'loan2_11', 'loan2_12', 'loan2_1_y', 'loan2_2_y', 'loan2_3_y', 'loan2_4_y', 'loan2_5_y', 'loan1_2_sum', 'loan1_3_sum', 'loan1_7_sum', 'loan1_9_sum', 'query_1', 'query_2', 'query_3', 'query_4', 'query_5', 'query_6', 'query_7', 'query_8', 'query_9', 'query_10', 'query_11', 'query_1_y', 'query_2_y', 'query_3_y', 'query_4_y', 'query_5_y', 'query_6_y']\n"
     ]
    }
   ],
   "source": [
    "# x_col = basic_col+loan_col+['nan_num'] + ['is_judicial']+ overdue_col+query_col\n",
    "# x_col = basic_col+['is_judicial']+loan_col+query_col+overdue_col+['scope_num'] + \\\n",
    "#     ['industry_num']+['date_3_count', 'date_1_std', 'date_1_diff_std']\n",
    "\n",
    "x_col = basic_col+['is_judicial']+loan_col+query_col\n",
    "x_col = [i for i in x_col if i in full_col_name]\n",
    "\n",
    "if cat_way == \"auto\":\n",
    "    type_col = [i for i in type_col if i in x_col]\n",
    "# categorize(df_train,type_col)\n",
    "# categorize(df_test,type_col)\n",
    "\n",
    "print('自变量个数为', len(x_col))\n",
    "print(x_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[x_col+['label', 'cust_id']]\n",
    "df_test = df_test[x_col+['cust_id']]\n",
    "\n",
    "df_test.to_csv(\"test_input.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对抗验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import xgboost as xgb\n",
    "\n",
    "df_full = pd.concat([df_train[x_col+['cust_id']], df_test],\n",
    "                    axis=0, ignore_index=True)\n",
    "df_full['label_test'] = [1 if i in df_test['cust_id']\n",
    "                         else 0 for i in df_full['cust_id']]\n",
    "\n",
    "df_full.to_csv(\"full.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.53742\ttest-auc:0.48914\n",
      "[1]\ttrain-auc:0.55191\ttest-auc:0.49196\n",
      "[2]\ttrain-auc:0.56448\ttest-auc:0.48941\n",
      "[3]\ttrain-auc:0.57097\ttest-auc:0.48939\n",
      "[4]\ttrain-auc:0.57264\ttest-auc:0.48918\n",
      "[5]\ttrain-auc:0.58560\ttest-auc:0.48826\n",
      "[6]\ttrain-auc:0.60419\ttest-auc:0.49118\n",
      "[7]\ttrain-auc:0.62184\ttest-auc:0.48914\n",
      "[8]\ttrain-auc:0.62841\ttest-auc:0.48934\n",
      "[9]\ttrain-auc:0.62960\ttest-auc:0.49048\n",
      "[10]\ttrain-auc:0.63976\ttest-auc:0.49032\n",
      "[11]\ttrain-auc:0.65147\ttest-auc:0.48990\n",
      "[12]\ttrain-auc:0.67397\ttest-auc:0.49606\n",
      "[13]\ttrain-auc:0.67884\ttest-auc:0.49567\n",
      "[14]\ttrain-auc:0.68668\ttest-auc:0.49713\n",
      "[15]\ttrain-auc:0.68765\ttest-auc:0.49723\n",
      "[16]\ttrain-auc:0.68938\ttest-auc:0.49691\n",
      "[17]\ttrain-auc:0.69727\ttest-auc:0.49696\n",
      "[18]\ttrain-auc:0.70277\ttest-auc:0.49562\n",
      "[19]\ttrain-auc:0.70564\ttest-auc:0.49539\n",
      "[20]\ttrain-auc:0.71053\ttest-auc:0.49735\n",
      "[21]\ttrain-auc:0.71422\ttest-auc:0.49628\n",
      "[22]\ttrain-auc:0.71625\ttest-auc:0.49607\n",
      "[23]\ttrain-auc:0.72043\ttest-auc:0.49590\n",
      "[24]\ttrain-auc:0.72535\ttest-auc:0.49675\n",
      "[25]\ttrain-auc:0.72711\ttest-auc:0.49799\n",
      "[26]\ttrain-auc:0.73226\ttest-auc:0.49797\n",
      "[27]\ttrain-auc:0.73382\ttest-auc:0.49856\n",
      "[28]\ttrain-auc:0.73612\ttest-auc:0.49865\n",
      "[29]\ttrain-auc:0.73989\ttest-auc:0.49872\n",
      "[30]\ttrain-auc:0.74677\ttest-auc:0.49818\n",
      "[31]\ttrain-auc:0.74792\ttest-auc:0.49807\n",
      "[32]\ttrain-auc:0.75376\ttest-auc:0.49854\n",
      "[33]\ttrain-auc:0.75486\ttest-auc:0.49775\n",
      "[34]\ttrain-auc:0.75603\ttest-auc:0.49797\n",
      "[35]\ttrain-auc:0.75641\ttest-auc:0.49748\n",
      "[36]\ttrain-auc:0.75685\ttest-auc:0.49786\n",
      "[37]\ttrain-auc:0.76153\ttest-auc:0.49721\n",
      "[38]\ttrain-auc:0.76533\ttest-auc:0.49688\n",
      "[39]\ttrain-auc:0.77167\ttest-auc:0.49576\n",
      "[40]\ttrain-auc:0.77582\ttest-auc:0.49737\n",
      "[41]\ttrain-auc:0.77611\ttest-auc:0.49739\n",
      "[42]\ttrain-auc:0.77683\ttest-auc:0.49761\n",
      "[43]\ttrain-auc:0.77870\ttest-auc:0.49768\n",
      "[44]\ttrain-auc:0.77919\ttest-auc:0.49782\n",
      "[45]\ttrain-auc:0.77945\ttest-auc:0.49739\n",
      "[46]\ttrain-auc:0.77985\ttest-auc:0.49646\n",
      "[47]\ttrain-auc:0.78217\ttest-auc:0.49635\n",
      "[48]\ttrain-auc:0.78429\ttest-auc:0.49710\n",
      "[49]\ttrain-auc:0.78645\ttest-auc:0.49604\n",
      "[50]\ttrain-auc:0.78740\ttest-auc:0.49629\n",
      "[51]\ttrain-auc:0.78859\ttest-auc:0.49664\n",
      "[52]\ttrain-auc:0.78951\ttest-auc:0.49700\n",
      "[53]\ttrain-auc:0.78978\ttest-auc:0.49715\n",
      "[54]\ttrain-auc:0.79031\ttest-auc:0.49768\n",
      "[55]\ttrain-auc:0.79292\ttest-auc:0.49716\n",
      "[56]\ttrain-auc:0.79589\ttest-auc:0.49801\n",
      "[57]\ttrain-auc:0.79873\ttest-auc:0.49905\n",
      "[58]\ttrain-auc:0.80009\ttest-auc:0.49757\n",
      "[59]\ttrain-auc:0.80117\ttest-auc:0.49826\n",
      "[60]\ttrain-auc:0.80544\ttest-auc:0.49749\n",
      "[61]\ttrain-auc:0.80575\ttest-auc:0.49712\n",
      "[62]\ttrain-auc:0.80610\ttest-auc:0.49690\n",
      "[63]\ttrain-auc:0.80821\ttest-auc:0.49740\n",
      "[64]\ttrain-auc:0.81150\ttest-auc:0.49700\n",
      "[65]\ttrain-auc:0.81296\ttest-auc:0.49667\n",
      "[66]\ttrain-auc:0.81657\ttest-auc:0.49671\n",
      "[67]\ttrain-auc:0.81764\ttest-auc:0.49592\n",
      "[68]\ttrain-auc:0.82201\ttest-auc:0.49521\n",
      "[69]\ttrain-auc:0.82479\ttest-auc:0.49593\n",
      "[70]\ttrain-auc:0.82942\ttest-auc:0.49607\n",
      "[71]\ttrain-auc:0.83115\ttest-auc:0.49616\n",
      "[72]\ttrain-auc:0.83278\ttest-auc:0.49550\n",
      "[73]\ttrain-auc:0.83398\ttest-auc:0.49589\n",
      "[74]\ttrain-auc:0.83496\ttest-auc:0.49518\n",
      "[75]\ttrain-auc:0.83764\ttest-auc:0.49506\n",
      "[76]\ttrain-auc:0.83935\ttest-auc:0.49445\n",
      "[77]\ttrain-auc:0.84211\ttest-auc:0.49470\n",
      "[78]\ttrain-auc:0.84253\ttest-auc:0.49444\n",
      "[79]\ttrain-auc:0.84294\ttest-auc:0.49477\n",
      "[80]\ttrain-auc:0.84358\ttest-auc:0.49470\n",
      "[81]\ttrain-auc:0.84566\ttest-auc:0.49508\n",
      "[82]\ttrain-auc:0.84813\ttest-auc:0.49487\n",
      "[83]\ttrain-auc:0.84875\ttest-auc:0.49446\n",
      "[84]\ttrain-auc:0.85102\ttest-auc:0.49380\n",
      "[85]\ttrain-auc:0.85363\ttest-auc:0.49310\n",
      "[86]\ttrain-auc:0.85365\ttest-auc:0.49356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_full[x_col+['cust_id']]\n",
    "Y = df_full['label_test']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(\n",
    "    X, Y, test_size=0.5, stratify=Y, random_state=2022)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[x_col], label=Y_train)\n",
    "dtest = xgb.DMatrix(X_test[x_col], label=Y_test)\n",
    "\n",
    "param = {'max_depth': 5,\n",
    "         'eta': 0.1,\n",
    "         'objective': 'binary:logistic',\n",
    "         \"eval_metric\": \"auc\",\n",
    "         \"scale_pos_weight\": 1,\n",
    "         \"subsample\": 1,\n",
    "         \"min_child_weight\": 1,\n",
    "         'tree_method': 'gpu_hist',\n",
    "         'gpu_id': 0, }\n",
    "\n",
    "bst = xgb.train(param, dtrain, 400, evals=[(dtrain, \"train\"), (dtest, \"test\")],\n",
    "                early_stopping_rounds=30, verbose_eval=True)\n",
    "bst1 = xgb.train(param, dtest, 400, evals=[(dtest, \"train\"), (dtrain, \"test\")],\n",
    "                 early_stopping_rounds=30, verbose_eval=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(\n",
    "    {'cust_id': X_test['cust_id'], 'p_test': bst.predict(dtest)})\n",
    "df_res1 = pd.DataFrame(\n",
    "    {'cust_id': X_train['cust_id'], 'p_test': bst1.predict(dtrain)})\n",
    "\n",
    "df = pd.concat([df_res, df_res1], axis=0, ignore_index=True)\n",
    "\n",
    "df_train = pd.merge(df_train, df, on=\"cust_id\",\n",
    "                    how=\"left\", suffixes=(\"\", \"_y\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过对抗验证，有17995条数据被保留，4条数据被抛弃\n"
     ]
    }
   ],
   "source": [
    "temp = len(df_train)\n",
    "df_train.to_csv(\"train_input.csv\", encoding='utf-8')\n",
    "\n",
    "df_train = df_train[df_train['p_test'] >= 0.1]\n",
    "\n",
    "\n",
    "print(\"经过对抗验证，有\", len(df_train), \"条数据被保留，\",\n",
    "      temp-len(df_train), \"条数据被抛弃\", sep=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 60\n",
    "num_round = 3000\n",
    "local_test_size = 3000\n",
    "\n",
    "# 共用\n",
    "test_size = [0.2, 0.3,0.4]\n",
    "max_depth = [3, 4, 5,7,8]\n",
    "subsample = [0.8, 0.75, 0.7, 0.65, 0.6]\n",
    "early_stopping_rounds = 150\n",
    "\n",
    "# XGB\n",
    "eta = [0.007, 0.01]\n",
    "gamma=[0,0.3,0.6,0.9]\n",
    "\n",
    "# LGB\n",
    "learning_rate = [0.03, 0.02, 0.025]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train划分为\n",
    "* 本地测试集（固定）d_localtest\n",
    "* 训练集（固定）\n",
    "  * 评估集（每次的模型不同）dtest\n",
    "  * 真正的训练集（每次的模型不同）dtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "\n",
    "pred_labels = []\n",
    "local_test_labels = []\n",
    "loss_seq = []\n",
    "max_auc_loss = 0\n",
    "flag = 0\n",
    "important_x_seq = []\n",
    "\n",
    "\n",
    "X = df_train[x_col]\n",
    "Y = df_train['label']\n",
    "\n",
    "X, X_local_test, Y, Y_local_test = model_selection.train_test_split(\n",
    "    X, Y, test_size=local_test_size, stratify=Y, random_state=2022)\n",
    "\n",
    "X_local_test2,X_local_test1,Y_local_test2,Y_local_test1=model_selection.train_test_split(X_local_test,Y_local_test,test_size=1000,stratify=Y_local_test)\n",
    "X_local_test3,X_local_test2,Y_local_test3,Y_local_test2=model_selection.train_test_split(X_local_test2,Y_local_test2,test_size=1000,stratify=Y_local_test2)\n",
    "\n",
    "X_local_test1_xgb=xgb.DMatrix(X_local_test1)\n",
    "X_local_test2_xgb=xgb.DMatrix(X_local_test2)\n",
    "X_local_test3_xgb=xgb.DMatrix(X_local_test3)\n",
    "\n",
    "d_localtest = xgb.DMatrix(X_local_test, label=Y_local_test)\n",
    "x_perd = xgb.DMatrix(df_test[x_col])\n",
    "\n",
    "d_localtest1 = lgb.Dataset(X_local_test, Y_local_test)\n",
    "x_perd1 = lgb.Dataset(df_test[x_col])\n",
    "\n",
    "\n",
    "lgbcallback = [early_stopping(early_stopping_rounds), log_evaluation(10000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'evals'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-69f1ea7b5fb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mbst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevallist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'evals'"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "for i in range(N):\n",
    "\n",
    "    test_size_this_round = random.choice(test_size)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, Y, test_size=test_size_this_round, stratify=Y)\n",
    "\n",
    "    #两种综合采样\n",
    "    #kos = SMOTETomek(random_state=0)\n",
    "    #X_kos,y_kos = kos.fit_sample(X_train,y_train)\n",
    "    #y_kos.sum()/len(y_kos)\n",
    "\n",
    "    kos = SMOTEENN(random_state=0)\n",
    "    X_kos,y_kos = kos.fit_resample(X_train,y_train)\n",
    "    #y_kos.sum()/len(y_kos)\n",
    "\n",
    "\n",
    "    X_train = X_kos\n",
    "    y_train = y_kos\n",
    "\n",
    "\n",
    "\n",
    "    # XGB-----------------------------------------------\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    evallist = [(dtest, 'eval')]\n",
    "    param = {\n",
    "        'max_depth': random.choice(max_depth),\n",
    "        'eta': random.choice(eta),\n",
    "        'objective': 'binary:logistic',\n",
    "        'gamma':random.choice(gamma),\n",
    "        'eval_metric': 'auc',\n",
    "        'subsample': random.choice(subsample),\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'gpu_id': 0,\n",
    "    }\n",
    "\n",
    "    bst=xgb.XGBClassifier()\n",
    "    bst.set_params(param)\n",
    "    bst.fit(dtrain,y_train)\n",
    "\n",
    "    bst = xgb.train(dtrain, num_round, evals=evallist,\n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose_eval=False)\n",
    "\n",
    "    loss = roc_auc_score(y_test, bst.predict(dtest))\n",
    "    train_loss = roc_auc_score(y_train, bst.predict(dtrain))\n",
    "    local_test_loss1 = roc_auc_score(Y_local_test1, bst.predict(X_local_test1_xgb))\n",
    "    local_test_loss2 = roc_auc_score(Y_local_test2, bst.predict(X_local_test2_xgb))\n",
    "    local_test_loss3 = roc_auc_score(Y_local_test3, bst.predict(X_local_test3_xgb))\n",
    "\n",
    "    pred_label = list(bst.predict(x_perd))\n",
    "\n",
    "    test_label = list(bst.predict(d_localtest))\n",
    "\n",
    "    temp_dict = {\"test_auc\": loss, \"train_auc\": train_loss,\n",
    "                 'local_test_auc1': local_test_loss1,\n",
    "                 'local_test_auc2': local_test_loss2,\n",
    "                 'local_test_auc3': local_test_loss3,\n",
    "                 'sum_test_loss':(loss+local_test_loss1+local_test_loss2+local_test_loss3)/4,\n",
    "                 'model': 'xgb'}\n",
    "\n",
    "    if flag == 0:\n",
    "        info_df = pd.DataFrame(temp_dict, index=[i])\n",
    "        flag = 1\n",
    "    else:\n",
    "        info_df = pd.concat([info_df, pd.DataFrame(temp_dict, index=[i])])\n",
    "\n",
    "    # if loss > max_auc_loss:\n",
    "    #     best_bst = copy.deepcopy(bst)\n",
    "    #     max_auc_loss = loss\n",
    "\n",
    "    # if False:\n",
    "    #     pic = xgb.plot_importance(bst, max_num_features=50)\n",
    "    #     temp = pic.get_ymajorticklabels()\n",
    "    #     important_x = [str(i).split(\"\\'\")[1] for i in temp]\n",
    "    #     important_x.reverse()\n",
    "    #     important_x_seq += important_x\n",
    "\n",
    "    pred_labels.append(copy.deepcopy(pred_label))\n",
    "    local_test_labels.append(copy.deepcopy(test_label))\n",
    "\n",
    "    # LGB--------------------------------------------------------\n",
    "    param = {\n",
    "        'task': 'train',\n",
    "        \"max_depth\": random.choice(max_depth),\n",
    "        'max_bin': 128,\n",
    "        'boosting_type': 'gbdt',  # 设置提升类型\n",
    "        'objective': 'binary',  # 目标函数\n",
    "        'metric': 'auc',  # 评估函数\n",
    "        'learning_rate': random.choice(learning_rate),  # 学习速率\n",
    "        'bagging_fraction': random.choice(subsample),  # 建树的样本采样比例\n",
    "        'bagging_freq': 1,  # k 意味着每 k 次迭代执行bagging\n",
    "        'min_data_in_leaf': 1,\n",
    "        'verbose': -1,  # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "        'device_type': 'gpu',\n",
    "    }\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, y_train)\n",
    "    dtest = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "    if cat_way == \"auto\":\n",
    "        bst1 = lgb.train(param, dtrain, num_round, valid_sets=[\n",
    "            dtest], callbacks=lgbcallback, categorical_feature=type_col)\n",
    "    else:\n",
    "        bst1 = lgb.train(param, dtrain, num_round, valid_sets=[\n",
    "            dtest], callbacks=lgbcallback)\n",
    "\n",
    "    loss = roc_auc_score(y_test, bst1.predict(X_test))\n",
    "    train_loss = roc_auc_score(y_train, bst1.predict(X_train))\n",
    "    local_test_loss1 = roc_auc_score(Y_local_test1, bst1.predict(X_local_test1))\n",
    "    local_test_loss2 = roc_auc_score(Y_local_test2, bst1.predict(X_local_test2))\n",
    "    local_test_loss3 = roc_auc_score(Y_local_test3, bst1.predict(X_local_test3))\n",
    "\n",
    "\n",
    "    pred_label = list(bst1.predict(df_test[x_col]))\n",
    "    test_label = list(bst1.predict(X_local_test))\n",
    "\n",
    "    temp_dict = {\"test_auc\": loss, \"train_auc\": train_loss,\n",
    "                 'local_test_auc1': local_test_loss1,\n",
    "                 'local_test_auc2': local_test_loss2,\n",
    "                 'local_test_auc3': local_test_loss3,\n",
    "                 'sum_test_loss':(loss+local_test_loss1+local_test_loss2+local_test_loss3)/4,\n",
    "                 'model': 'lgb'}\n",
    "\n",
    "    info_df = pd.concat([info_df, pd.DataFrame(temp_dict, index=[i])])\n",
    "    pred_labels.append(copy.deepcopy(pred_label))\n",
    "    local_test_labels.append(copy.deepcopy(test_label))\n",
    "\n",
    "    # CAT-----------------------------------------------------------\n",
    "    # bst2 = CatBoostClassifier(iterations=num_round,\n",
    "    #                        depth=random.choice(max_depth),\n",
    "    #                        learning_rate=random.choice(learning_rate),\n",
    "    #                        loss_function='Logloss',\n",
    "    #                        subsample=random.choice(subsample),\n",
    "    #                        early_stopping_rounds=early_stopping_rounds,\n",
    "    #                        verbose=False)\n",
    "    # bst2.fit(X_train, y_train,eval_set=(X_test,y_test))\n",
    "\n",
    "    # loss = roc_auc_score(y_test, bst2.predict_proba(X_test)[:,1])\n",
    "    # train_loss = roc_auc_score(y_train, bst2.predict_proba(X_train)[:,1])\n",
    "    # local_test_loss = roc_auc_score(Y_local_test, bst2.predict_proba(X_local_test)[:,1])\n",
    "    # global_auc = roc_auc_score(df_train['label'], bst2.predict_proba(df_train[x_col])[:,1])\n",
    "\n",
    "    # pred_label = list(bst2.predict_proba(df_test[x_col])[:,1])\n",
    "    # test_label = list(bst2.predict_proba(X_local_test)[:,1])\n",
    "\n",
    "    # temp_dict = {\"test_auc\": loss, \"train_auc\": train_loss,\n",
    "    #              'local_test_auc': local_test_loss,\n",
    "    #              'model': 'cat'}\n",
    "\n",
    "    # info_df = pd.concat([info_df, pd.DataFrame(temp_dict, index=[i])])\n",
    "    # pred_labels.append(copy.deepcopy(pred_label))\n",
    "    # local_test_labels.append(copy.deepcopy(test_label))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.to_csv(\"info.csv\", encoding=\"utf-8\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pic = xgb.plot_importance(bst, max_num_features=50)\n",
    "# temp = pic.get_ymajorticklabels()\n",
    "# important_x = [str(i).split(\"\\'\")[1] for i in temp]\n",
    "# important_x.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.value_counts(important_x_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6.5, 6), dpi=200)\n",
    "\n",
    "\n",
    "plt.scatter(info_df[info_df['model'] == 'xgb']['sum_test_loss'], info_df[info_df['model'] == 'xgb']['test_auc'],\n",
    "            c='r', s=4, label=\"xgb\")\n",
    "plt.scatter(info_df[info_df['model'] == 'lgb']['sum_test_loss'], info_df[info_df['model'] == 'lgb']['test_auc'],\n",
    "            c='g', s=4, label=\"lgb\")\n",
    "# plt.scatter(info_df[info_df['model'] == 'cat']['local_test_auc'], info_df[info_df['model'] == 'cat']['test_auc'],\n",
    "#             c='b', s=4,label=\"cat\")\n",
    "plt.legend()\n",
    "plt.xlabel('local_test_auc')\n",
    "plt.ylabel('sum_auc')\n",
    "plt.plot([0.6, 0.85], [0.6, 0.85])\n",
    "plt.xlim(0.6, 0.85)\n",
    "plt.ylim(0.6, 0.85)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "xgb_res=[]\n",
    "lgb_res=[]\n",
    "temp=list(info_df['model'])\n",
    "for i in range(N*2):\n",
    "    if temp[i]==\"xgb\":\n",
    "        xgb_res+=copy.deepcopy(local_test_labels[i])\n",
    "    if temp[i]==\"lgb\":\n",
    "        lgb_res+=copy.deepcopy(local_test_labels[i])\n",
    "\n",
    "log_reg=LogisticRegression()\n",
    "res_df=pd.DataFrame({\"xgb\":xgb_res,'lgb':lgb_res,'real':list(Y_local_test)*N})\n",
    "\n",
    "log_reg.fit(res_df[['xgb','lgb']],res_df['real'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.boxplot(['xgb','lgb'],by='real',figsize=[20,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5), dpi=200)\n",
    "plt.scatter(xgb_res,lgb_res,s=0.5,c=list(Y_local_test)*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "date = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "res_num = np.argsort(\n",
    "    [-i for i in (info_df['sum_test_loss'])])\n",
    "\n",
    "# 选择前n个结果进行平均（手动指定or在本地测试集排序选出）\n",
    "if True:\n",
    "    max_auc = -1\n",
    "    list_temp = []\n",
    "    auc_seq = []\n",
    "    for i in range(N*2):\n",
    "        list_temp.append(local_test_labels[res_num[i]])\n",
    "        # 算数平均\n",
    "        # temp = np.mean(list_temp, axis=0)\n",
    "        # 几何平均(better)\n",
    "        temp = np.exp(np.mean(np.log(list_temp), axis=0))\n",
    "        temp_auc = roc_auc_score(Y_local_test, temp)\n",
    "        # print(i, temp_auc)\n",
    "        auc_seq.append(temp_auc)\n",
    "        if temp_auc > max_auc:\n",
    "            max_auc = temp_auc\n",
    "            n = i+1\n",
    "else:\n",
    "    n = 40\n",
    "    n = min(N, n)\n",
    "\n",
    "res_num = res_num[0:n]\n",
    "\n",
    "#final_pred_label = np.mean([pred_labels[i] for i in res_num], axis=0)\n",
    "final_pred_label = np.exp(\n",
    "    np.mean(np.log([pred_labels[i] for i in res_num]), axis=0))\n",
    "#local_auc = roc_auc_score(y_test, final_pred_label)\n",
    "\n",
    "print(\"平均\",n,\"个结果之后local_test_AUC为\", max_auc, sep=\"\")\n",
    "\n",
    "res = pd.DataFrame({\n",
    "    'cust_id': list(df_test[\"cust_id\"]),\n",
    "    'label': final_pred_label,\n",
    "})\n",
    "res.to_csv(\"./output/result\"+date+\".csv\", encoding=\"utf-8\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6), dpi=200)\n",
    "plt.plot(list(range(len(auc_seq))), auc_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一些tips\n",
    "\n",
    "* 提升n有一定提升(如何确定n？)\n",
    "  * n=40 0.6763\n",
    "  * n=10 0.6728\n",
    "  * n=100 0.6774\n",
    "  * 太大也不好\n",
    "\n",
    "# 一些进展\n",
    "\n",
    "* 随机参数\n",
    "* XGB模型\n",
    "* 本地测试集auc较高（0.75+）\n",
    "* 部分类型变量进行了one-hot处理\n",
    "* 把细分表除了loan与主表合并\n",
    "\n",
    "# tbd\n",
    "\n",
    "* 处理细分表的loan，给出指标\n",
    "* 确定变量类型，以便对所有（or重要）分类变量进行one-hot处理\n",
    "* 新模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-12\n",
    "* 0.6824（这次我留了代码\\doge）\n",
    "* 把-99变为-1，本地有提升\n",
    "* 划出了一个本地测试集\n",
    "  * 本地测试集（固定）d_localtest\n",
    "  * 训练集（固定）\n",
    "    * 评估集（每次的模型不同）dtest\n",
    "    * 真正的训练集（每次的模型不同）dtrain\n",
    "* 添加参数nan_num（然并卵）\n",
    "* tbd\n",
    "  * 找特征\n",
    "  * 加x\n",
    "  * 分析一下参数作用\n",
    "## 10-18\n",
    "* 不能把industry之类种类很多的分类变量做证据权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 记录\n",
    "* 1014-4\n",
    "  * 0.6823\n",
    "  * 证据权重\n",
    "  * 未添加贷款记录表\n",
    "  * 按test auc排序\n",
    "* 1014-5\n",
    "  * 0.6925\n",
    "  * 按local test auc排序\n",
    "* 1015-1\n",
    "  * 0.6834\n",
    "  * 处理-99\n",
    "* 1015-2\n",
    "  * 0.6628\n",
    "  * 添加贷款记录表\n",
    "* 1015-3\n",
    "  * 0.6772\n",
    "  * 不处理-99\n",
    "  * 去除贷款记录表\n",
    "  * 添加了type-col\n",
    "* 1015-4\n",
    "  * 0.6811\n",
    "  * 不做证据权重\n",
    "* 1015-5\n",
    "  * 0.6765\n",
    "  * gamma=0\n",
    "* 1016-1\n",
    "  * 0.6798\n",
    "  * 添加gamma\n",
    "  * 增大early stop round\n",
    "* 1016-2\n",
    "  * 0.6858\n",
    "  * early stop round=10\n",
    "  * 证据权重\n",
    "* 1016-3\n",
    "  * 0.685799\n",
    "  * 使用原始type-col\n",
    "* 1017-2\n",
    "  * 0.6655\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
